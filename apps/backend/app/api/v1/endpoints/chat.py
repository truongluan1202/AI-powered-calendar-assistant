"""Chat endpoints - Pure LLM service without database operations."""

import json
import re
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional

from app.services.llm_service import LLMService
from app.services.gemini_provider import LLMMessage
from app.services.tools import get_tools_for_provider


def clean_confirmation_format(content: str) -> str:
    """Clean up any remaining old confirmation format elements from the content."""
    # Remove the old format elements
    content = re.sub(r"^---\s*\n?", "", content, flags=re.MULTILINE)
    content = re.sub(r"\n?---\s*$", "", content, flags=re.MULTILINE)
    content = re.sub(r"üìÖ\s*\*\*Event Details:\*\*\s*\n?", "", content)
    content = re.sub(
        r"Please confirm: Type \'confirm\' to create or \'modify \[details\]\' to change something\.\s*\n?",
        "",
        content,
    )

    # Clean up any extra whitespace
    content = re.sub(r"\n\s*\n\s*\n+", "\n\n", content)
    content = content.strip()

    return content


def get_context_aware_response(tool_calls):
    """Generate context-aware responses based on tool calls to match frontend optimistic messages."""
    print(f"üîç DEBUG: Getting context-aware response for tool calls: {tool_calls}")

    if not tool_calls:
        print("üîç DEBUG: No tool calls, using default fallback")
        return "I didn't quite catch that. Could you please rephrase your question or try asking again? I'm here to help with your calendar and any other questions you might have!"

    # Check for handleEventConfirmation tool calls
    for tool_call in tool_calls:
        if tool_call.get("function", {}).get("name") == "handleEventConfirmation":
            try:
                args = json.loads(tool_call.get("function", {}).get("arguments", "{}"))
                action = args.get("action", "")
                event_details = args.get("eventDetails", {})
                print(f"üîç DEBUG: Found handleEventConfirmation with action: {action}")

                if action == "confirm":
                    # Extract event title for more personalized response
                    event_title = (
                        event_details.get("summary", "your event")
                        if event_details
                        else "your event"
                    )
                    print(
                        f"üîç DEBUG: Returning personalized confirm response for: {event_title}"
                    )
                    return f"{event_title} has been created successfully! Is there anything else I can help you with?"
                elif action == "modify":
                    # Extract event title for more personalized response
                    event_title = (
                        event_details.get("summary", "your event")
                        if event_details
                        else "your event"
                    )
                    print(
                        f"üîç DEBUG: Returning personalized modify response for: {event_title}"
                    )
                    return f"{event_title} has been updated successfully! Is there anything else I can help you with?"
            except (json.JSONDecodeError, KeyError) as e:
                print(f"üîç DEBUG: Error parsing handleEventConfirmation args: {e}")
                # Fallback to generic response
                return "Event operation completed successfully! Is there anything else I can help you with?"

    # Check for getEvents tool calls
    for tool_call in tool_calls:
        if tool_call.get("function", {}).get("name") == "getEvents":
            print("üîç DEBUG: Found getEvents, returning 'Here are your events:'")
            return "üìÖ Here are your events:"

    # Check for webSearch tool calls
    for tool_call in tool_calls:
        if tool_call.get("function", {}).get("name") == "webSearch":
            try:
                args = json.loads(tool_call.get("function", {}).get("arguments", "{}"))
                query = args.get("query", "")
                print(f"üîç DEBUG: Found webSearch for query: {query}")
                return f"üîç I found information about '{query}'. Let me know if you'd like to create an event based on this!"
            except (json.JSONDecodeError, KeyError) as e:
                print(f"üîç DEBUG: Error parsing webSearch args: {e}")
                return "üîç I found some information for you. Let me know if you'd like to create an event based on this!"

    # Check for createEvent tool calls (if any)
    for tool_call in tool_calls:
        if tool_call.get("function", {}).get("name") == "createEvent":
            print("üîç DEBUG: Found createEvent, returning creation response")
            return "Event created successfully! Is there anything else I can help you with?"

    # Check for updateEvent tool calls (if any)
    for tool_call in tool_calls:
        if tool_call.get("function", {}).get("name") == "updateEvent":
            print("üîç DEBUG: Found updateEvent, returning update response")
            return "Event updated successfully! Is there anything else I can help you with?"

    # Check for deleteEvent tool calls (if any)
    for tool_call in tool_calls:
        if tool_call.get("function", {}).get("name") == "deleteEvent":
            print("üîç DEBUG: Found deleteEvent, returning deletion response")
            return "Event deleted successfully! Is there anything else I can help you with?"

    # Default fallback
    print("üîç DEBUG: No matching tool calls, using default fallback")
    return "I didn't quite catch that. Could you please rephrase your question or try asking again? I'm here to help with your calendar and any other questions you might have!"


router = APIRouter()

# Initialize LLM service
llm_service = LLMService()


class Message(BaseModel):
    """Message structure for LLM requests."""

    role: str
    content: str


class GenerateRequest(BaseModel):
    """Request structure for LLM generation."""

    messages: List[Message]
    model_provider: str
    model_name: str


class GenerateResponse(BaseModel):
    """Response structure from LLM generation."""

    content: str
    provider: str
    model: str
    usage: Optional[Dict[str, Any]] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None


@router.post("/generate", response_model=GenerateResponse)
async def generate_llm_response(request: GenerateRequest):
    """Generate LLM response without any database operations."""
    try:

        # Convert messages to LLM format
        llm_messages = [
            LLMMessage(role=msg.role, content=msg.content) for msg in request.messages
        ]

        # Check if provider is available
        if not llm_service.is_provider_available(request.model_provider):
            raise HTTPException(
                status_code=400,
                detail=f"LLM provider {request.model_provider} is not available",
            )

        # Get tools for the provider
        tools = get_tools_for_provider(request.model_provider)

        # Use unified response generation for all queries
        llm_response = await llm_service.generate_response(
            provider=request.model_provider,
            messages=llm_messages,
            model=request.model_name,
            tools=tools,
        )

        print("üîç DEBUG: LLM Response received:")
        print(f"üîç DEBUG: - Content: '{llm_response.content[:200]}...'")
        print(f"üîç DEBUG: - Provider: {llm_response.provider}")
        print(f"üîç DEBUG: - Model: {llm_response.model}")
        print(f"üîç DEBUG: - Tool calls: {llm_response.tool_calls}")
        print(f"üîç DEBUG: - Number of tool calls: {len(llm_response.tool_calls)}")

        # Handle webSearch tool calls internally, others by frontend
        if llm_response.tool_calls:
            web_search_calls = [
                call
                for call in llm_response.tool_calls
                if call["function"]["name"] == "webSearch"
            ]
            other_calls = [
                call
                for call in llm_response.tool_calls
                if call["function"]["name"] != "webSearch"
            ]

            if web_search_calls:
                # Handle webSearch tool calls internally
                tool_results = []
                updated_messages = llm_messages.copy()

                # Add the assistant's response with tool calls
                updated_messages.append(
                    LLMMessage(
                        role="assistant",
                        content=llm_response.content,
                        tool_calls=llm_response.tool_calls,
                    )
                )

                # Execute webSearch tool calls
                for tool_call in web_search_calls:
                    try:
                        result = await llm_service.execute_tool_call(tool_call)
                        tool_results.append(result)
                    except NotImplementedError:
                        # Tool not implemented in backend, skip it
                        pass

                # Add tool results to conversation
                tool_results_message = LLMMessage(
                    role="tool", content=json.dumps(tool_results)
                )
                updated_messages.append(tool_results_message)

                print("üîç DEBUG: Tool results added to conversation:")
                print(f"üîç DEBUG: - Tool results: {tool_results}")
                print(
                    f"üîç DEBUG: - Tool results message: {tool_results_message.content}"
                )

                # Generate final response with tool results
                print("üîç DEBUG: Calling LLM with updated messages:")
                print(f"üîç DEBUG: - Number of messages: {len(updated_messages)}")
                for i, msg in enumerate(updated_messages):
                    print(
                        f"üîç DEBUG: - Message {i}: {msg.role} - {msg.content[:100]}..."
                    )

                final_response = await llm_service.generate_response(
                    provider=request.model_provider,
                    messages=updated_messages,
                    model=request.model_name,
                    tools=tools,
                )

                print("üîç DEBUG: Final response after tool execution:")
                print(f"üîç DEBUG: - Content: '{final_response.content[:200]}...'")
                print(f"üîç DEBUG: - Tool calls: {final_response.tool_calls}")
                print(
                    f"üîç DEBUG: - Content length: {len(final_response.content) if final_response.content else 0}"
                )

                # Ensure we never return empty content
                content = (
                    final_response.content.strip() if final_response.content else ""
                )
                if not content:
                    # Fallback for empty responses after tool execution
                    print(
                        "üîç DEBUG: Empty content detected after web search, using context-aware fallback"
                    )
                    content = get_context_aware_response(llm_response.tool_calls)
                    print(f"üîç DEBUG: Context-aware fallback content: '{content}'")

                # Clean up any remaining old confirmation format elements
                content = clean_confirmation_format(content)

                final_response_obj = GenerateResponse(
                    content=content,
                    provider=final_response.provider,
                    model=final_response.model,
                    usage=final_response.usage,
                    tool_calls=final_response.tool_calls,
                )

                print("üîç DEBUG: Final response (with web search):")
                print(f"üîç DEBUG: - Content: '{final_response_obj.content[:200]}...'")
                print(f"üîç DEBUG: - Tool calls: {final_response_obj.tool_calls}")

                return final_response_obj
            else:
                # Only non-webSearch tool calls, return them for frontend handling
                # Ensure we never return empty content
                content = llm_response.content.strip() if llm_response.content else ""
                if not content:
                    # Only use context-aware response if there are tool calls that would trigger optimistic messages
                    if llm_response.tool_calls and any(
                        call.get("function", {}).get("name")
                        in [
                            "handleEventConfirmation",
                            "getEvents",
                            "createEvent",
                            "updateEvent",
                            "deleteEvent",
                        ]
                        for call in llm_response.tool_calls
                    ):
                        print(
                            "üîç DEBUG: Empty content with tool calls, using context-aware fallback"
                        )
                        content = get_context_aware_response(llm_response.tool_calls)
                    else:
                        print(
                            "üîç DEBUG: Empty content without relevant tool calls, using generic fallback"
                        )
                        content = "I didn't quite catch that. Could you please rephrase your question or try asking again? I'm here to help with your calendar and any other questions you might have!"

                # Clean up any remaining old confirmation format elements
                content = clean_confirmation_format(content)

                final_response_obj = GenerateResponse(
                    content=content,
                    provider=llm_response.provider,
                    model=llm_response.model,
                    usage=llm_response.usage,
                    tool_calls=other_calls,
                )

                print("üîç DEBUG: Final response (no web search):")
                print(f"üîç DEBUG: - Content: '{final_response_obj.content[:200]}...'")
                print(f"üîç DEBUG: - Tool calls: {final_response_obj.tool_calls}")

                return final_response_obj

        # Ensure we never return empty content
        content = llm_response.content.strip() if llm_response.content else ""
        if not content:
            # Only use context-aware response if there are tool calls that would trigger optimistic messages
            if llm_response.tool_calls and any(
                call.get("function", {}).get("name")
                in [
                    "handleEventConfirmation",
                    "getEvents",
                    "createEvent",
                    "updateEvent",
                    "deleteEvent",
                ]
                for call in llm_response.tool_calls
            ):
                print(
                    "üîç DEBUG: Empty content with tool calls, using context-aware fallback"
                )
                content = get_context_aware_response(llm_response.tool_calls)
            else:
                print(
                    "üîç DEBUG: Empty content without relevant tool calls, using generic fallback"
                )
                content = "I didn't quite catch that. Could you please rephrase your question or try asking again? I'm here to help with your calendar and any other questions you might have!"

        # Clean up any remaining old confirmation format elements
        content = clean_confirmation_format(content)

        final_response_obj = GenerateResponse(
            content=content,
            provider=llm_response.provider,
            model=llm_response.model,
            usage=llm_response.usage,
            tool_calls=llm_response.tool_calls,
        )

        print("üîç DEBUG: Final response (no tool calls):")
        print(f"üîç DEBUG: - Content: '{final_response_obj.content[:200]}...'")
        print(f"üîç DEBUG: - Tool calls: {final_response_obj.tool_calls}")

        return final_response_obj

    except Exception as e:
        import traceback

        # Log the full error for debugging
        traceback.print_exc()

        # The Gemini provider already converts errors to user-friendly messages
        # So we can use the error message directly
        error_message = str(e)
        print(f"üîç DEBUG: Error message: {error_message}")

        # If the error message already looks user-friendly, use it directly
        if any(
            phrase in error_message.lower()
            for phrase in [
                "currently overloaded",
                "temporarily unavailable",
                "too many requests",
                "authentication error",
                "please try again",
                "please wait",
            ]
        ):
            user_friendly_message = error_message
        else:
            # Fallback for unexpected errors
            user_friendly_message = "I encountered an unexpected error. Please try again, and if the problem persists, please contact support."

        # Return a 200 response with the user-friendly error message instead of raising an exception
        return GenerateResponse(
            content=user_friendly_message,
            provider="gemini",
            model="gemini-2.5-flash",
            usage={},
            tool_calls=[],
        )


@router.get("/providers")
async def get_available_providers():
    """Get list of available LLM providers."""
    return {
        "available_providers": ["gemini"],
        "providers": {
            "gemini": {
                "available": llm_service.is_provider_available("gemini"),
                "models": [
                    "gemini-2.5-flash-lite",
                    "gemini-2.0-flash-lite",
                    "gemini-2.5-flash",
                    "gemini-2.0-flash",
                ],
            },
        },
    }
